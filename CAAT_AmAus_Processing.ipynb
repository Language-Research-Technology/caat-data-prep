{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b35ae53b-4423-4171-b077-ffc8e196d25f",
   "metadata": {},
   "source": [
    "# CAAT AmAus Data Processing\n",
    "\n",
    "This notebook is used for processing the plain Corpus of Americans and Australians Talking (CAAT) AmAus Word documents, without any conversation analysis markup.\n",
    "\n",
    "This notebook requires a single DOCX input file, and outputs a transformed CSV.\n",
    "\n",
    "Some of the cells in this notebook require the user to update the variables according to the document or review the cell output, and these are prefixed with the **User Input** and **User Review** labels respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e5d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Before we begin, let's make sure that we install all the requirements that we need\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5170cc22-62c2-4b0a-b261-c1e6e206e75f",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321bf73d-85db-488c-9c53-5bc036a34f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e9737-6c22-46e2-952f-f7c15f265bf3",
   "metadata": {},
   "source": [
    "## **User Input**: Specify document location\n",
    "\n",
    "Edit the sections in quotes to specify the file path and name of the Word document. If the document is in the same location as this notebook is being run, keep the default `AmAus01-31 transcripts_June2025 version`, otherwise update it. `.docx` is not needed at the end of the document name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee7d240-a738-480b-b1b0-5feecffe5e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_directory = \"AmAus01-31 transcripts_June2025 version\"\n",
    "document_name = \"AmAus07_transcript_plain\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e744578-2f7c-4c71-a5f0-dd778ff4bdfe",
   "metadata": {},
   "source": [
    "## Load document as text\n",
    "\n",
    "The document is loaded as plain text. The following fixes are also applied:\n",
    "- space and tab combinations directly after the speaker code converted to single tab\n",
    "- colon added after speaker code if missing\n",
    "- tabs not dividing the speaker and text columns converted to space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ebb7e-409b-4edb-8480-1fd58942fb94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the document\n",
    "doc_path = Path(document_directory) / f\"{document_name}.docx\"\n",
    "doc = Document(doc_path)\n",
    "\n",
    "# Extract text from all paragraphs\n",
    "full_text = []\n",
    "for paragraph in doc.paragraphs:\n",
    "    full_text.append(paragraph.text)\n",
    "\n",
    "# Join all paragraphs into a single string\n",
    "text_content = '\\n'.join(full_text)\n",
    "\n",
    "# Fix space and tab combinations after speaker code, and add colon after speaker code if missing\n",
    "text_content = re.sub(r'^[\\t ]+', r'\\t', text_content, flags=re.MULTILINE)\n",
    "text_content = re.sub(r'^([A-Z]):[\\t ]+', r'\\1:\\t', text_content, flags=re.MULTILINE)\n",
    "text_content = re.sub(r'^([A-Z])[\\t ]+', r'\\1:\\t', text_content, flags=re.MULTILINE)\n",
    "\n",
    "# Replace \" \\t\" with just space if the line already contains a tab before it\n",
    "text_content = re.sub(r'(\\t.*) \\t', r'\\1 ', text_content, flags=re.MULTILINE)\n",
    "\n",
    "print(text_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ce649-dcc6-4cef-a9f3-05f90302bba1",
   "metadata": {},
   "source": [
    "## **User Review**: Restructure data if speaker tags are missing\n",
    "\n",
    "For any lines missing speakers, if the speaker occurs in the line above, that line will be attached to the end of the previous one, adding a space between the sections if not already present. If an 'END OF TRANSCRIPT' line occurs, this will also be removed.\n",
    "\n",
    "This step will also output a `changes_log.txt` file to the same folder as your input file for review of all changes applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f0867-4f83-4a5b-ae1b-9073d593fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove END OF TRANSCRIPT line\n",
    "text_content = re.sub(r'^.*END OF TRANSCRIPT.*$', r'', text_content, flags=re.MULTILINE)\n",
    "\n",
    "rules = [\n",
    "    (re.compile(r'^([A-Z]:)(\\t.* $)\\n\\t(.*)$', re.MULTILINE), r'\\1\\2\\3'),\n",
    "    (re.compile(r'^([A-Z]:)(\\t.*[^ ]$)\\n\\t(.*)$', re.MULTILINE), r'\\1\\2 \\3'),\n",
    "    (re.compile(r'^([A-Z]:)(\\t.*?)(?:\\s*)\\n(?![A-Z]:)([^\\n]+)$', re.MULTILINE), None),\n",
    "]\n",
    "\n",
    "with open(\"changes_log.txt\", \"w\", encoding=\"utf-8\") as log:\n",
    "    while True:\n",
    "        total_changes = 0\n",
    "\n",
    "        for pat, repl in rules:\n",
    "\n",
    "            def replacer(match):\n",
    "                before = match.group(0)\n",
    "\n",
    "                speaker = match.group(1)\n",
    "                col2 = match.group(2)\n",
    "                continuation = match.group(3).lstrip()\n",
    "\n",
    "                after = f\"{speaker}{col2} {continuation}\"\n",
    "\n",
    "                log.write(\"CHANGED:\\n\")\n",
    "                log.write(before)\n",
    "                log.write(\"\\n→\\n\")\n",
    "                log.write(after)\n",
    "                log.write(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
    "\n",
    "                return after\n",
    "\n",
    "            text_content, n = pat.subn(replacer, text_content)\n",
    "            total_changes += n\n",
    "\n",
    "        if total_changes == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0a8c1a-f779-40bb-88a2-8c44f838a68f",
   "metadata": {},
   "source": [
    "## Convert text to a Pandas DataFrame\n",
    "\n",
    "Tab-separated text is converted to columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf809b-d0c2-4a31-bae3-c22e32c42d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split columns only when tabs exist and make each line a row\n",
    "rows = [line.split(\"\\t\") for line in text_content.splitlines()]\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190aba41-cc4c-49ec-95ef-ee565d030981",
   "metadata": {},
   "source": [
    "## **User Review**: Check rows with empty cells\n",
    "\n",
    "The output here should only contain the header and footer sections. Any other output indicates there may be missing or incorrect data in the Word document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9012107c-dc08-4fce-b77f-e6162fdcf780",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_cells = df[(df.isna() | (df == \"\")).any(axis=1)]\n",
    "print(empty_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93075dfe-6d78-4442-adb3-14351a1b1030",
   "metadata": {},
   "source": [
    "## **User Input**: Identify header and footer sections to remove\n",
    "\n",
    "Edit the numbers to specify how many lines to remove from the start and the end of the document, so that only the speaker and transcript section is left. Use the index from the previous cell to check the header and footer. For the header, add 1 to the last index number of the header as the count starts from zero. Note that this includes paragraph breaks. If there is no footer, set the number to `0`.\n",
    "\n",
    "```\n",
    "0    Transcript: xxx\n",
    "1    Recording date: xxx\n",
    "2    Length of audio recording: xxx\n",
    "3    Length of video recording: xxx\n",
    "4    Transcriber: xxx\n",
    "5   \n",
    "6    Speakers:\n",
    "7    A:\txxx\n",
    "8    B:\txxx\n",
    "9    C:\txxx\n",
    "10   \n",
    "11   \n",
    "```\n",
    "Last row of header is index 11 = 12 rows\n",
    "\n",
    "...\n",
    "```\n",
    "430  END OF TRANSCRIPT\n",
    "```\n",
    "1 row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991df4b5-0c8f-4b25-8bfb-4756ff58e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_rows = 11\n",
    "footer_rows = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29475739-b7a9-4624-b01b-22e6cab0c1ed",
   "metadata": {},
   "source": [
    "## Remove header and footer sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7589230c-6f23-4dfa-a65e-5e2b561324b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove header section\n",
    "df = df.iloc[header_rows:].reset_index(drop=True)\n",
    "\n",
    "# Remove footer section\n",
    "df.drop(df.tail(footer_rows).index, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad0233-70e9-43ba-b057-da8c2b70f350",
   "metadata": {},
   "source": [
    "## Remove any rows where the entire line is blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cba383-6abe-45e5-8068-46369e5f18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows where all cells are NaN or empty string\n",
    "rows_to_delete = df[(df.isna() | df.eq(\"\")).all(axis=1)]\n",
    "\n",
    "# Print rows being removed\n",
    "for idx in rows_to_delete.index:\n",
    "    print(f\"Removing empty row at index: {idx}\")\n",
    "else:\n",
    "    print(\"No empty rows\")\n",
    "\n",
    "# Remove the rows\n",
    "df = df[~((df.isna() | df.eq(\"\")).all(axis=1))]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9febca99-741a-4e45-976c-cfa42ce6606e",
   "metadata": {},
   "source": [
    "## **User Review**: Check for any rows that contain empty cells\n",
    "\n",
    "If the output is Empty DataFrame, there are no empty cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a1835-92f5-4442-9ea0-80fc195e0083",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_cells = df[(df.isna() | (df == \"\")).any(axis=1)]\n",
    "print(empty_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99dfb37-b668-4cd7-b4cf-4a68db8f90c1",
   "metadata": {},
   "source": [
    "## Add column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d856d-6237-42fe-a6c5-787e2e1d0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['speakerID', 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cc854-32ae-40b1-8f3c-ee8217716ee1",
   "metadata": {},
   "source": [
    "## **User Input**: Specify speaker and RA codes\n",
    "\n",
    "Update the sections in quotes with the code in the `speakerID` column, the name of the speaker, and the code in the RO-Crate metadata spreadsheet (these are found in the `@id` column in the People tab). Scroll up to the output of 'Load document as text' if you need to see the speaker list again.\n",
    "\n",
    "At least one American speaker, Australian speaker and research assistant (RA) will be required for all documents, but if there are more speakers involved, add these in the additional participants section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cc923-f817-4889-916a-39d04fb78bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# American speaker\n",
    "am_speaker_orig = \"D:\"\n",
    "am_speaker_name = \"John Smith\"\n",
    "am_speaker_new = \"#AmM03\"\n",
    "\n",
    "# Australian speaker\n",
    "aus_speaker_orig = \"E:\"\n",
    "aus_speaker_name = \"Jane Smith\"\n",
    "aus_speaker_new = \"#AusF05\"\n",
    "\n",
    "# Research Assistant\n",
    "ra_orig = \"L:\"\n",
    "ra_name = \"Joan Smith\"\n",
    "ra_new = \"#AusF02\"\n",
    "\n",
    "## Additional participants if needed\n",
    "extra_speaker1_orig = \"G:\"\n",
    "extra_speaker1_name = \"John Smith\"\n",
    "extra_speaker1_new = \"#AusF04\"\n",
    "\n",
    "extra_speaker2_orig = \"Z:\"\n",
    "extra_speaker2_name = \"Jane Smith\"\n",
    "extra_speaker2_new = \"#AusF04\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee598c89-3d00-4193-8327-d60a5e3315cf",
   "metadata": {},
   "source": [
    "## Update speakerIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6c36b-ec9b-4e6d-8499-1cace916554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"speakerID\"] = df[\"speakerID\"].replace(to_replace=am_speaker_orig, value=am_speaker_new)\n",
    "df[\"speakerID\"] = df[\"speakerID\"].replace(to_replace=aus_speaker_orig, value=aus_speaker_new)\n",
    "df[\"speakerID\"] = df[\"speakerID\"].replace(to_replace=ra_orig, value=ra_new)\n",
    "df[\"speakerID\"] = df[\"speakerID\"].replace(to_replace=extra_speaker1_orig, value=extra_speaker1_new)\n",
    "df[\"speakerID\"] = df[\"speakerID\"].replace(to_replace=extra_speaker2_orig, value=extra_speaker2_new)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b58dfe-f39a-4ddf-ba78-d614eab697f3",
   "metadata": {},
   "source": [
    "## **User Review**: Check for any rows where the speakerID wasn't updated\n",
    "\n",
    "If the output is Empty DataFrame, there are no errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defcb4c1-987e-4c49-b6a8-98b4301528be",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = df[~df[\"speakerID\"].str.contains(\"#\", na=False)]\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ae4a25-5f68-491c-86c0-4d3eec7647cd",
   "metadata": {},
   "source": [
    "## Add 'name' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382dd9f-7aec-4a78-8845-0ebd2859711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(1, \"name\", \"\")\n",
    "df.loc[df[\"speakerID\"] == am_speaker_new, \"name\"] = am_speaker_name\n",
    "df.loc[df[\"speakerID\"] == aus_speaker_new, \"name\"] = aus_speaker_name\n",
    "df.loc[df[\"speakerID\"] == ra_new, \"name\"] = ra_name\n",
    "df.loc[df[\"speakerID\"] == extra_speaker1_new, \"name\"] = extra_speaker1_name\n",
    "df.loc[df[\"speakerID\"] == extra_speaker2_new, \"name\"] = extra_speaker2_name\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e0545-78a7-45dc-b24d-7651eea9a87a",
   "metadata": {},
   "source": [
    "## Add 'section' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5052e45a-8999-4222-8a6c-9af7f19a8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add section columns\n",
    "df.insert(loc=3, column='section', value='MAIN')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de6043c-07e8-40a2-8e99-77c63ba69297",
   "metadata": {},
   "source": [
    "## Remove any time codes\n",
    "\n",
    "This step will search for any timecodes in formats like `(~0:33)` and `(~10:00)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579aaeb3-61f4-4fc8-9ad2-71452a5a0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = df[\"text\"].copy()\n",
    "\n",
    "df[\"text\"] = df[\"text\"].str.replace(r'^\\([\\~0-9][\\~0-9:\\.]*\\) ', '', regex=True)\n",
    "df[\"text\"] = df[\"text\"].str.replace(r' \\([\\~0-9][\\~0-9:\\.]*\\) ', ' ', regex=True)\n",
    "df[\"text\"] = df[\"text\"].str.replace(r' \\([\\~0-9][\\~0-9:\\.]*\\)$', ' ', regex=True)\n",
    "df[\"text\"] = df[\"text\"].str.replace(r'^\\([\\~0-9][\\~0-9:\\.]*\\)', '', regex=True)\n",
    "df[\"text\"] = df[\"text\"].str.replace(r'\\([\\~0-9][\\~0-9:\\.]*\\)', ' ', regex=True)\n",
    "df[\"text\"] = df[\"text\"].str.replace(r'\\([\\~0-9][\\~0-9:\\.]*\\)$', ' ', regex=True)\n",
    "\n",
    "with open(\"timecodes_log.txt\", \"w\", encoding=\"utf-8\") as log:\n",
    "    for i, (b, a) in enumerate(zip(before, df[\"text\"])):\n",
    "        if b != a:\n",
    "            log.write(\"CHANGED:\\n\")\n",
    "            log.write(str(b) + \"\\n\")\n",
    "            log.write(\"→\\n\")\n",
    "            log.write(str(a) + \"\\n\")\n",
    "            log.write(\"-\" * 40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da71d9-8263-4934-93ac-7cb460a57b3a",
   "metadata": {},
   "source": [
    "## Clean characters in DataFrame\n",
    "\n",
    "Applies some minor character encoding fixes for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47254a93-279d-47c2-8ed5-680e54ca7fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    '“': '\"',\n",
    "    '”': '\"',\n",
    "    '‘': \"'\",\n",
    "    '’': \"'\",\n",
    "    '—': '-',\n",
    "    '–': '-',\n",
    "}\n",
    "\n",
    "def clean_text(val):\n",
    "    if isinstance(val, str):\n",
    "        val = val.strip()\n",
    "        for old, new in replacements.items():\n",
    "            val = val.replace(old, new)\n",
    "    return val\n",
    "\n",
    "df_clean = df.map(clean_text)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25734ec5-2652-4b68-b4b1-6420470d0ad4",
   "metadata": {},
   "source": [
    "## **User Review**: Review characters in cleaned DataFrame\n",
    "\n",
    "A list of all the characters in the dataframe is printed below. Scan through the list to check these are all expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed14be-49d4-426d-9b11-d48d7bc9ba0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chars = set(\"\".join(df_clean.astype(str).stack()))\n",
    "char_list = sorted(chars)\n",
    "\n",
    "for c in char_list:\n",
    "    code = f\"U+{ord(c):04X}\"\n",
    "    try:\n",
    "        name = unicodedata.name(c)\n",
    "    except ValueError:\n",
    "        name = \"<NO NAME>\"\n",
    "    print(f\"{c!r}  {code}  {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a204385-637b-4383-83a3-037abaefb6a1",
   "metadata": {},
   "source": [
    "## **User Input**: Identify preamble rows\n",
    "\n",
    "The 'section' column is pre-populated by default with MAIN in each row. Run the cell below to view the first 20 rows of the document. If you can't see the final line of the preamble, increase `20` to a higher number and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e8782-edf2-4101-b91d-e4ff7a63ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0dd5c-0da8-4469-b11c-76cd5f7b0855",
   "metadata": {},
   "source": [
    "## **User Input**: Update preamble range\n",
    "\n",
    "Edit the numbers below with the correct range of the preamble, using the index column numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9a34b-b491-421e-8537-3db5b90e965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_row_start = 0\n",
    "pre_row_end = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce6050-220a-422b-b097-2da8252ab599",
   "metadata": {},
   "source": [
    "## **User Input**: Identify postamble rows\n",
    "\n",
    "The 'section' column is pre-populated by default with MAIN in each row. Run the cell below to view the last 20 rows of the document. If you can't see the first line of the postamble, increase `20` to a higher number and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57134093-18fd-4b93-9f51-b9bfa10e2da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1fd1c2-e737-47b8-8499-fa8cc7341694",
   "metadata": {},
   "source": [
    "## **User Input**: Update postamble range\n",
    "\n",
    "Edit the numbers below with the correct range of the postamble, using the index column numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0034657-37c3-40a7-a786-21933ec6f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_row_start = 564\n",
    "post_row_end = 566"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed57eaef-1b71-4851-8759-d251f35f6540",
   "metadata": {},
   "source": [
    "## Update DataFrame with PRE and POST sections\n",
    "\n",
    "This will use the ranges specified previously to update MAIN to PRE and POST where applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82100d9c-a879-46d0-a89e-1bf639c3b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.loc[pre_row_start:pre_row_end, \"section\"] = \"PRE\"\n",
    "df_clean.loc[post_row_start:post_row_end, \"section\"] = \"POST\"\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825103f9-a42a-4adb-8163-a78a88eeeda1",
   "metadata": {},
   "source": [
    "## Export final version to CSV\n",
    "\n",
    "This will create a CSV version of the finalised document and save it in the same location as this notebook. It uses the same document name as the input Word document, e.g. AmAus01_transcript_plain.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e1ad0-1347-4e4a-b75a-a5ecaa8ae1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(f\"{document_name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
